---
layout:     post                    
title:      数据预处理方法总结               
subtitle:   数据预处理方法包括相似度、抽样以及降维等方法 
date:       2019-02-20             
author:     xinxin                     
header-img: img/post-bg-rwd.jpg    
catalog: true                       
mathjax: true
tags:                               
    - 数据预处理
---

## 数据预处理方法总结

数据是什么？数据就是一组对象及其属性的集合，其中属性定义为对象的特征或性质。真实数据在应用前基本都有经过预处理，以便在机器学习算法中使用。本次数据预处理方法的总结是基于推荐系统设计进行展开的，其中包括相似度的度量方法、抽样以及降维技术这三个尤为重要的问题。

### 相似度度量方法

* 在相似度度量方法中，最简单、最常用的就是欧几里得距离：

$$
{\rm{d}}(x,y) = \sqrt {\sum\limits_{k = 1}^n {(x_k  - y_k )^2 } } 
$$

其中，n是维数（属性数），$${x_k }$$和$${y_k }$$分别是数据对象x和y的第k个属性值。

* 闵可夫斯基距离是欧几里得距离的推广：

$$
{\rm{d}}(x,y) = (\sum\limits_{k = 1}^n {|x_k  - y_k |^r } )^{\frac{1}{r}} 
$$

其中，r是距离的度（参数）。取决于r值的不同，一般的闵可夫斯基距离有专用的名称：

r=1,城市街区（也叫曼哈顿距离、出租车、L1范数）距离。

r=2,欧几里得距离（L2范数）。

r=$$\infty$$,上确界（$$L_{\max }$$或$$L_\infty$$范数），这是任意维度对象属性间的最大距离。

* 马氏距离：

$$
{\rm{d}}(x,y) = \sqrt {(x - y)\sigma ^{ - 1} (x - y)^T } 
$$

其中，$$\sigma$$是数据的协方差矩阵。

* 把对象看作是n维空间的文档向量，并计算它们相似度作为形成夹角的余弦值，其公式为：

$$
\cos (x,y) = \frac{(xy)}{\left\| x \right\|\left\| y \right\|}
$$

其中，dot表示向量的点积，$${\left\| x \right\|}$$是向量x的长度。这个相似度称为余弦相似度或L2范数。

* 皮尔逊相关系数(通过给出点x和y的协方差及它们的标准差$$\sigma $$)：

$$
Peason(x,y) = \frac{\sum {(x,y)} }{\sigma _x  \times \sigma _y }
$$

最后，在一些只有二进制属性的物品案例中，可以采用SMC或Jaccard系数的相似性度量方法。首先，计算M01、M10、M11和M00数量，其中M01表示x是0并且y是1这个属性的数量，M10表示x是1并且y是0这个属性的数量，依次类推。据此可计算出简单匹配系数$$SMC = \frac{M11 + M00}{M01 + M10 + M00 + M11}$$;jaccard系数$$JC = \frac{M11}{M01 + M10 + M11}$$。广义Jaccard系数，是JC关于连续值属性或计数属性的一个变型，$$d = \frac{xy}{\left\| x \right\|^2  + \left\| y \right\|^2  - xy}$$



说明：本文资料来自于《推荐系统中的数据挖掘方法》




